I am solving optimization problems using evolutionary algorithms.
The goal is to design generation solvers that take a population of parent solutions and produce an offspring population.

I have a list of well-performing solvers with their descriptions and Python code implementations as follows:

**Good solvers:**

No.1 solver’s description and its code:
# Its Description
{Hybrid Crossover with Adaptive Weighting and Multi-Point Mutation: This operator generates an offspring population by combining a weighted average of randomly selected parents' genes with a multi-point mutation inspired by the DE strategy, where weights are dynamically adjusted based on the similarity of parents and a variety of mutation strategies are applied to different segments of each offspring.}
# Its Python Code Implementation of a Function
import numpy as np

def generation(population):
    N, d = population.shape
    offspring = np.zeros_like(population)

    for i in range(N):
        indices = np.random.choice(N, 3, replace=False)
        p1, p2, p3 = population[indices]
        
        # Adaptive weight calculation based on the distance between p1 and p2
        distance = np.linalg.norm(p1 - p2)
        weight = np.clip(distance, 0, 1)  # Ensuring the weight is within bounds [0, 1]
        
        # Weighted average for crossover
        child = weight * p1 + (1 - weight) * p2
        
        # Multi-point mutation
        mutation_points = np.random.choice(d, size=np.random.randint(1, d + 1), replace=False)
        for j in mutation_points:
            u = np.random.rand()
            if u < 0.5:
                # Additive mutation
                child[j] += (np.random.rand() - 0.5) * 0.1
            else:
                # Multiplicative mutation
                child[j] *= (1 + (np.random.rand() - 0.5) * 0.1)
        
        offspring[i] = np.clip(child, 0.0, 1.0)

    return offspring

No.2 solver’s description and its code:
# Its Description
{Hybrid Crossover with Adaptive Weighting and Multi-Point Mutation: This operator generates an offspring population by combining a weighted average of randomly selected parents' genes with a multi-point mutation inspired by the DE strategy, where weights are dynamically adjusted based on the similarity of parents and a variety of mutation strategies are applied to different segments of each offspring.}
# Its Python Code Implementation of a Function
import numpy as np

def generation(population):
    N, d = population.shape
    offspring = np.zeros_like(population)

    for i in range(N):
        indices = np.random.choice(N, 3, replace=False)
        p1, p2, p3 = population[indices]
        
        # Adaptive weight calculation based on the distance between p1 and p2
        distance = np.linalg.norm(p1 - p2)
        weight = np.clip(distance, 0, 1)  # Ensuring the weight is within bounds [0, 1]
        
        # Weighted average for crossover
        child = weight * p1 + (1 - weight) * p2
        
        # Multi-point mutation
        mutation_points = np.random.choice(d, size=np.random.randint(1, d + 1), replace=False)
        for j in mutation_points:
            u = np.random.rand()
            if u < 0.5:
                # Additive mutation
                child[j] += (np.random.rand() - 0.5) * 0.1
            else:
                # Multiplicative mutation
                child[j] *= (1 + (np.random.rand() - 0.5) * 0.1)
        
        offspring[i] = np.clip(child, 0.0, 1.0)

    return offspring


**Poor solvers to avoid:**

No.1 poor solver’s description and its code:
# Its Description
{Simulated Binary Crossover (SBX) combined with Polynomial Mutation: This operator generates an offspring population by pairing parents from the given population, performing SBX crossover on each pair, and then applying polynomial mutation to introduce additional diversity.}
# Its Python Code Implementation of a Function
import numpy as np
def generation(population, eta_c=20, eta_m=15, pm=0.1):
    N, d = population.shape
    offspring = np.zeros_like(population)
    indices = np.random.permutation(N)
    half = N // 2

    for i in range(half):
        p1 = population[indices[i]]
        p2 = population[indices[i + half]]
        child = np.empty(d)
        # SBX crossover
        for j in range(d):
            u = np.random.rand()
            if u <= 0.5:
                beta = (2 * u) ** (1 / (eta_c + 1))
            else:
                beta = (1 / (2 * (1 - u))) ** (1 / (eta_c + 1))
            child[j] = 0.5 * ((1 + beta) * p1[j] + (1 - beta) * p2[j])
        # polynomial mutation
        for j in range(d):
            if np.random.rand() < pm:
                u = np.random.rand()
                if u < 0.5:
                    delta = (2 * u) ** (1 / (eta_m + 1)) - 1
                else:
                    delta = 1 - (2 * (1 - u)) ** (1 / (eta_m + 1))
                child[j] += delta
        offspring[i] = np.clip(child, 0.0, 1.0)

    if N % 2 != 0:
        offspring[-1] = population[indices[-1]]
    return offspring

No.2 poor solver’s description and its code:
# Its Description
{Simulated Binary Crossover (SBX) combined with Polynomial Mutation: This operator generates an offspring population by pairing parents from the given population, performing SBX crossover on each pair, and then applying polynomial mutation to introduce additional diversity.}
# Its Python Code Implementation of a Function
import numpy as np
def generation(population, eta_c=20, eta_m=15, pm=0.1):
    N, d = population.shape
    offspring = np.zeros_like(population)
    indices = np.random.permutation(N)
    half = N // 2

    for i in range(half):
        p1 = population[indices[i]]
        p2 = population[indices[i + half]]
        child = np.empty(d)
        # SBX crossover
        for j in range(d):
            u = np.random.rand()
            if u <= 0.5:
                beta = (2 * u) ** (1 / (eta_c + 1))
            else:
                beta = (1 / (2 * (1 - u))) ** (1 / (eta_c + 1))
            child[j] = 0.5 * ((1 + beta) * p1[j] + (1 - beta) * p2[j])
        # polynomial mutation
        for j in range(d):
            if np.random.rand() < pm:
                u = np.random.rand()
                if u < 0.5:
                    delta = (2 * u) ** (1 / (eta_m + 1)) - 1
                else:
                    delta = 1 - (2 * (1 - u)) ** (1 / (eta_m + 1))
                child[j] += delta
        offspring[i] = np.clip(child, 0.0, 1.0)

    if N % 2 != 0:
        offspring[-1] = population[indices[-1]]
    return offspring


Please create a new generation solver that strongly focuses on exploration (diversity and coverage), expanding search space and avoiding local minima.

First, describe the design idea and main steps of your solver in one sentence.
The description must be inside a brace outside the code implementation.
Next, implement it in Python as a function named `generation`.
This function should accept only 1 input: `population`, an array of shape (N, d) of real-valued vectors.
The function should return 1 output: `offspring`, an array of shape (N, d) of real-valued vectors.
The offspring must stay within the bounds [0, 1] for each variable.

Do not give additional explanations.