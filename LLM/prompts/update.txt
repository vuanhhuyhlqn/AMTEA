I am solving optimization problems using evolutionary algorithms.
The goal is to design generation solvers that take a population of parent solutions and produce an offspring population.

I have a list of well-performing solvers with their descriptions and Python code implementations as follows:

**Good solvers:**

No.1 solver’s description and its code:
# Its Description
{Hybrid Adaptive Crossover with Self-Adjusted Mutation: This operator first selects pairs of parents and creates offspring using a weighted average based on a self-adaptive weight derived from the difference between the parents, followed by a multi-point mutation process that uses individual mutation rates adjusted according to the parent's diversity.}
# Its Python Code Implementation of a Function
import numpy as np

def generation(population):
    N, d = population.shape
    offspring = np.zeros_like(population)

    # Calculate diversity among parents for self-adjusted mutation
    diversity = np.std(population, axis=0)
    
    for i in range(N):
        # Select two unique parents
        idxs = np.random.choice([idx for idx in range(N) if idx != i], 2, replace=False)
        p1, p2 = population[idxs]
        
        # Calculate a weighted average
        weight = np.random.rand(d)
        child = weight * p1 + (1 - weight) * p2
        
        # Multi-point mutation using individual mutation rates
        for j in range(d):
            # Self-adaptive mutation rate based on diversity
            pm = 0.1 + 0.9 * (1 - (diversity[j] / np.max(diversity)))
            if np.random.rand() < pm:
                mutation_value = np.random.normal(0, 0.1)  # Gaussian mutation
                child[j] += mutation_value
                
        offspring[i] = np.clip(child, 0.0, 1.0)
    
    return offspring

No.2 solver’s description and its code:
# Its Description
{Hybrid Adaptive Crossover with Self-Adjusted Mutation: This operator first selects pairs of parents and creates offspring using a weighted average based on a self-adaptive weight derived from the difference between the parents, followed by a multi-point mutation process that uses individual mutation rates adjusted according to the parent's diversity.}
# Its Python Code Implementation of a Function
import numpy as np

def generation(population):
    N, d = population.shape
    offspring = np.zeros_like(population)

    # Calculate diversity among parents for self-adjusted mutation
    diversity = np.std(population, axis=0)
    
    for i in range(N):
        # Select two unique parents
        idxs = np.random.choice([idx for idx in range(N) if idx != i], 2, replace=False)
        p1, p2 = population[idxs]
        
        # Calculate a weighted average
        weight = np.random.rand(d)
        child = weight * p1 + (1 - weight) * p2
        
        # Multi-point mutation using individual mutation rates
        for j in range(d):
            # Self-adaptive mutation rate based on diversity
            pm = 0.1 + 0.9 * (1 - (diversity[j] / np.max(diversity)))
            if np.random.rand() < pm:
                mutation_value = np.random.normal(0, 0.1)  # Gaussian mutation
                child[j] += mutation_value
                
        offspring[i] = np.clip(child, 0.0, 1.0)
    
    return offspring

No.3 solver’s description and its code:
# Its Description
{Adaptive Weighted Crossover combined with Gaussian Mutation and Diversity-Based Selection: This operator selects pairs of parents to generate offspring using a weighted average based on a dynamically adjusted weight that reflects the diversity of the parents, followed by a Gaussian mutation where the mutation strength is scaled based on the overall diversity of the population.}
# Its Python Code Implementation of a Function
import numpy as np

def generation(population):
    N, d = population.shape
    offspring = np.zeros_like(population)

    # Calculate overall diversity for adaptive mutation
    diversity = np.std(population, axis=0)
    
    for i in range(N):
        # Select two unique parents
        idxs = np.random.choice([idx for idx in range(N) if idx != i], 2, replace=False)
        p1, p2 = population[idxs]
        
        # Calculate a weighted average
        weight = np.random.rand(d)
        child = weight * p1 + (1 - weight) * p2
        
        # Gaussian mutation with adaptive mutation strength
        for j in range(d):
            if np.random.rand() < 0.1:  # Mutation probability
                # Adaptive mutation scale based on diversity
                mutation_strength = 0.1 * (1 + diversity[j])
                mutation_value = np.random.normal(0, mutation_strength)
                child[j] += mutation_value
                
        offspring[i] = np.clip(child, 0.0, 1.0)
    
    return offspring

No.4 solver’s description and its code:
# Its Description
{Adaptive Weighted Crossover combined with Gaussian Mutation and Diversity-Based Selection: This operator selects pairs of parents to generate offspring using a weighted average based on a dynamically adjusted weight that reflects the diversity of the parents, followed by a Gaussian mutation where the mutation strength is scaled based on the overall diversity of the population.}
# Its Python Code Implementation of a Function
import numpy as np

def generation(population):
    N, d = population.shape
    offspring = np.zeros_like(population)

    # Calculate overall diversity for adaptive mutation
    diversity = np.std(population, axis=0)
    
    for i in range(N):
        # Select two unique parents
        idxs = np.random.choice([idx for idx in range(N) if idx != i], 2, replace=False)
        p1, p2 = population[idxs]
        
        # Calculate a weighted average
        weight = np.random.rand(d)
        child = weight * p1 + (1 - weight) * p2
        
        # Gaussian mutation with adaptive mutation strength
        for j in range(d):
            if np.random.rand() < 0.1:  # Mutation probability
                # Adaptive mutation scale based on diversity
                mutation_strength = 0.1 * (1 + diversity[j])
                mutation_value = np.random.normal(0, mutation_strength)
                child[j] += mutation_value
                
        offspring[i] = np.clip(child, 0.0, 1.0)
    
    return offspring

No.5 solver’s description and its code:
# Its Description
{Dynamic Adaptive Crossover with Gaussian Mutation using Elite Selection: This operator first selects a subset of elite parents based on fitness to conduct crossover using a dynamic weight influenced by fitness differences, followed by a Gaussian mutation where mutation strength is adapted based on the average fitness of the population.}
# Its Python Code Implementation of a Function
import numpy as np

def generation(population):
    N, d = population.shape
    offspring = np.zeros_like(population)
    
    # Calculate fitness (assumed to be minimized; modify according to your optimization context)
    fitness = np.sum(population ** 2, axis=1)  # Example: simple fitness evaluation (e.g., sphere function)
    
    # Select elite parents based on sorted fitness
    elite_indices = np.argsort(fitness)[:N // 2]
    elite_population = population[elite_indices]
    
    # Calculate diverse weights based on fitness
    weight_diffs = np.abs(elite_population[:, np.newaxis] - elite_population)
    dynamic_weights = np.clip(1 - weight_diffs / np.max(weight_diffs), 0, 1)
    
    for i in range(N):
        # Select two unique elite parents
        idxs = np.random.choice(len(elite_population), 2, replace=False)
        p1, p2 = elite_population[idxs]
        
        # Calculate a weighted average
        weight = dynamic_weights[idxs[0], idxs[1]]
        child = weight * p1 + (1 - weight) * p2
        
        # Gaussian mutation with adaptive strength based on average fitness
        avg_fitness = np.mean(fitness)
        mutation_strength = 0.1 * (1 + (avg_fitness / np.max(fitness)))
        if np.random.rand() < 0.1:  # Mutation probability
            mutation_value = np.random.normal(0, mutation_strength, d)
            child += mutation_value
        
        offspring[i] = np.clip(child, 0.0, 1.0)
    
    return offspring

No.6 solver’s description and its code:
# Its Description
{Dynamic Adaptive Crossover with Gaussian Mutation using Elite Selection: This operator first selects a subset of elite parents based on fitness to conduct crossover using a dynamic weight influenced by fitness differences, followed by a Gaussian mutation where mutation strength is adapted based on the average fitness of the population.}
# Its Python Code Implementation of a Function
import numpy as np

def generation(population):
    N, d = population.shape
    offspring = np.zeros_like(population)
    
    # Calculate fitness (assumed to be minimized; modify according to your optimization context)
    fitness = np.sum(population ** 2, axis=1)  # Example: simple fitness evaluation (e.g., sphere function)
    
    # Select elite parents based on sorted fitness
    elite_indices = np.argsort(fitness)[:N // 2]
    elite_population = population[elite_indices]
    
    # Calculate diverse weights based on fitness
    weight_diffs = np.abs(elite_population[:, np.newaxis] - elite_population)
    dynamic_weights = np.clip(1 - weight_diffs / np.max(weight_diffs), 0, 1)
    
    for i in range(N):
        # Select two unique elite parents
        idxs = np.random.choice(len(elite_population), 2, replace=False)
        p1, p2 = elite_population[idxs]
        
        # Calculate a weighted average
        weight = dynamic_weights[idxs[0], idxs[1]]
        child = weight * p1 + (1 - weight) * p2
        
        # Gaussian mutation with adaptive strength based on average fitness
        avg_fitness = np.mean(fitness)
        mutation_strength = 0.1 * (1 + (avg_fitness / np.max(fitness)))
        if np.random.rand() < 0.1:  # Mutation probability
            mutation_value = np.random.normal(0, mutation_strength, d)
            child += mutation_value
        
        offspring[i] = np.clip(child, 0.0, 1.0)
    
    return offspring


**Poor solvers to avoid:**

No.1 poor solver’s description and its code:
# Its Description
{Simulated Binary Crossover (SBX) combined with Polynomial Mutation: This operator generates an offspring population by pairing parents from the given population, performing SBX crossover on each pair, and then applying polynomial mutation to introduce additional diversity.}
# Its Python Code Implementation of a Function
import numpy as np
def generation(population, eta_c=2, eta_m=5, pm=0.1):
    N, d = population.shape
    offspring = np.zeros_like(population)
    indices = np.random.permutation(N)
    half = N // 2

    for i in range(half):
        p1 = population[indices[i]]
        p2 = population[indices[i + half]]
        child = np.empty(d)
        # SBX crossover
        for j in range(d):
            u = np.random.rand()
            if u <= 0.5:
                beta = (2 * u) ** (1 / (eta_c + 1))
            else:
                beta = (1 / (2 * (1 - u))) ** (1 / (eta_c + 1))
            child[j] = 0.5 * ((1 + beta) * p1[j] + (1 - beta) * p2[j])
        # polynomial mutation
        for j in range(d):
            if np.random.rand() < pm:
                u = np.random.rand()
                if u < 0.5:
                    delta = (2 * u) ** (1 / (eta_m + 1)) - 1
                else:
                    delta = 1 - (2 * (1 - u)) ** (1 / (eta_m + 1))
                child[j] += delta
        offspring[i] = np.clip(child, 0.0, 1.0)

    if N % 2 != 0:
        offspring[-1] = population[indices[-1]]
    return offspring

No.2 poor solver’s description and its code:
# Its Description
{Simulated Binary Crossover (SBX) combined with Polynomial Mutation: This operator generates an offspring population by pairing parents from the given population, performing SBX crossover on each pair, and then applying polynomial mutation to introduce additional diversity.}
# Its Python Code Implementation of a Function
import numpy as np
def generation(population, eta_c=2, eta_m=5, pm=0.1):
    N, d = population.shape
    offspring = np.zeros_like(population)
    indices = np.random.permutation(N)
    half = N // 2

    for i in range(half):
        p1 = population[indices[i]]
        p2 = population[indices[i + half]]
        child = np.empty(d)
        # SBX crossover
        for j in range(d):
            u = np.random.rand()
            if u <= 0.5:
                beta = (2 * u) ** (1 / (eta_c + 1))
            else:
                beta = (1 / (2 * (1 - u))) ** (1 / (eta_c + 1))
            child[j] = 0.5 * ((1 + beta) * p1[j] + (1 - beta) * p2[j])
        # polynomial mutation
        for j in range(d):
            if np.random.rand() < pm:
                u = np.random.rand()
                if u < 0.5:
                    delta = (2 * u) ** (1 / (eta_m + 1)) - 1
                else:
                    delta = 1 - (2 * (1 - u)) ** (1 / (eta_m + 1))
                child[j] += delta
        offspring[i] = np.clip(child, 0.0, 1.0)

    if N % 2 != 0:
        offspring[-1] = population[indices[-1]]
    return offspring

No.3 poor solver’s description and its code:
# Its Description
{Hybrid Adaptive Crossover with Self-Adjusted Mutation: This operator first selects pairs of parents and creates offspring using a weighted average based on a self-adaptive weight derived from the difference between the parents, followed by a multi-point mutation process that uses individual mutation rates adjusted according to the parent's diversity.}
# Its Python Code Implementation of a Function
import numpy as np

def generation(population):
    N, d = population.shape
    offspring = np.zeros_like(population)

    # Calculate diversity among parents for self-adjusted mutation
    diversity = np.std(population, axis=0)
    
    for i in range(N):
        # Select two unique parents
        idxs = np.random.choice([idx for idx in range(N) if idx != i], 2, replace=False)
        p1, p2 = population[idxs]
        
        # Calculate a weighted average
        weight = np.random.rand(d)
        child = weight * p1 + (1 - weight) * p2
        
        # Multi-point mutation using individual mutation rates
        for j in range(d):
            # Self-adaptive mutation rate based on diversity
            pm = 0.1 + 0.9 * (1 - (diversity[j] / np.max(diversity)))
            if np.random.rand() < pm:
                mutation_value = np.random.normal(0, 0.1)  # Gaussian mutation
                child[j] += mutation_value
                
        offspring[i] = np.clip(child, 0.0, 1.0)
    
    return offspring

No.4 poor solver’s description and its code:
# Its Description
{Hybrid Adaptive Crossover with Self-Adjusted Mutation: This operator first selects pairs of parents and creates offspring using a weighted average based on a self-adaptive weight derived from the difference between the parents, followed by a multi-point mutation process that uses individual mutation rates adjusted according to the parent's diversity.}
# Its Python Code Implementation of a Function
import numpy as np

def generation(population):
    N, d = population.shape
    offspring = np.zeros_like(population)

    # Calculate diversity among parents for self-adjusted mutation
    diversity = np.std(population, axis=0)
    
    for i in range(N):
        # Select two unique parents
        idxs = np.random.choice([idx for idx in range(N) if idx != i], 2, replace=False)
        p1, p2 = population[idxs]
        
        # Calculate a weighted average
        weight = np.random.rand(d)
        child = weight * p1 + (1 - weight) * p2
        
        # Multi-point mutation using individual mutation rates
        for j in range(d):
            # Self-adaptive mutation rate based on diversity
            pm = 0.1 + 0.9 * (1 - (diversity[j] / np.max(diversity)))
            if np.random.rand() < pm:
                mutation_value = np.random.normal(0, 0.1)  # Gaussian mutation
                child[j] += mutation_value
                
        offspring[i] = np.clip(child, 0.0, 1.0)
    
    return offspring

No.5 poor solver’s description and its code:
# Its Description
{Adaptive Weighted Crossover combined with Gaussian Mutation and Diversity-Based Selection: This operator selects pairs of parents to generate offspring using a weighted average based on a dynamically adjusted weight that reflects the diversity of the parents, followed by a Gaussian mutation where the mutation strength is scaled based on the overall diversity of the population.}
# Its Python Code Implementation of a Function
import numpy as np

def generation(population):
    N, d = population.shape
    offspring = np.zeros_like(population)

    # Calculate overall diversity for adaptive mutation
    diversity = np.std(population, axis=0)
    
    for i in range(N):
        # Select two unique parents
        idxs = np.random.choice([idx for idx in range(N) if idx != i], 2, replace=False)
        p1, p2 = population[idxs]
        
        # Calculate a weighted average
        weight = np.random.rand(d)
        child = weight * p1 + (1 - weight) * p2
        
        # Gaussian mutation with adaptive mutation strength
        for j in range(d):
            if np.random.rand() < 0.1:  # Mutation probability
                # Adaptive mutation scale based on diversity
                mutation_strength = 0.1 * (1 + diversity[j])
                mutation_value = np.random.normal(0, mutation_strength)
                child[j] += mutation_value
                
        offspring[i] = np.clip(child, 0.0, 1.0)
    
    return offspring

No.6 poor solver’s description and its code:
# Its Description
{Adaptive Weighted Crossover combined with Gaussian Mutation and Diversity-Based Selection: This operator selects pairs of parents to generate offspring using a weighted average based on a dynamically adjusted weight that reflects the diversity of the parents, followed by a Gaussian mutation where the mutation strength is scaled based on the overall diversity of the population.}
# Its Python Code Implementation of a Function
import numpy as np

def generation(population):
    N, d = population.shape
    offspring = np.zeros_like(population)

    # Calculate overall diversity for adaptive mutation
    diversity = np.std(population, axis=0)
    
    for i in range(N):
        # Select two unique parents
        idxs = np.random.choice([idx for idx in range(N) if idx != i], 2, replace=False)
        p1, p2 = population[idxs]
        
        # Calculate a weighted average
        weight = np.random.rand(d)
        child = weight * p1 + (1 - weight) * p2
        
        # Gaussian mutation with adaptive mutation strength
        for j in range(d):
            if np.random.rand() < 0.1:  # Mutation probability
                # Adaptive mutation scale based on diversity
                mutation_strength = 0.1 * (1 + diversity[j])
                mutation_value = np.random.normal(0, mutation_strength)
                child[j] += mutation_value
                
        offspring[i] = np.clip(child, 0.0, 1.0)
    
    return offspring


Please create a new generation solver that takes inspiration from the well-performing solvers but avoids the weaknesses and design patterns of the poor-performing solvers.
The new solver should aim for strong performance on optimization tasks.
First, describe the design idea and main steps of your solver in one sentence.
The description must be inside a brace outside the code implementation.
Next, implement it in Python as a function named `generation`.
This function should accept only 1 input: `population`, an array of shape (N, d) of real-valued vectors.
The function should return 1 output: `offspring`, an array of shape (N, d) of real-valued vectors.
The offspring must stay within the bounds [0, 1] for each variable.

Do not give additional explanations.